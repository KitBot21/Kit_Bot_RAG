#!/usr/bin/env python3
"""
RAG Demo: Qdrant Retrieval + LLM Generation
"""
import pandas as pd
from pathlib import Path
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from openai import OpenAI
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

PROJECT_ROOT = Path(__file__).resolve().parent

class RAGSystem:
    def __init__(self, collection_name='kit_corpus_bge_all', 
                 retriever_model='BAAI/bge-m3',
                 llm_provider='openai',  # 'openai' or 'ollama'
                 llm_model='gpt-4o-mini'):
        """
        RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            collection_name: Qdrant ì»¬ë ‰ì…˜ ì´ë¦„
            retriever_model: ì„ë² ë”© ëª¨ë¸
            llm_provider: LLM ì œê³µì ('openai' or 'ollama')
            llm_model: LLM ëª¨ë¸ ì´ë¦„
        """
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # Retriever ë¡œë“œ
        print(f"  ğŸ“¥ Retriever ë¡œë”©: {retriever_model}")
        self.retriever = SentenceTransformer(retriever_model)
        
        # Qdrant í´ë¼ì´ì–¸íŠ¸
        self.qdrant_client = QdrantClient('localhost', port=6333)
        self.collection_name = collection_name
        
        # LLM ì„¤ì •
        self.llm_provider = llm_provider
        self.llm_model = llm_model
        
        if llm_provider == 'openai':
            self.llm_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        elif llm_provider == 'ollama':
            # OllamaëŠ” ë¡œì»¬ì—ì„œ ì‹¤í–‰ (http://localhost:11434)
            self.llm_client = OpenAI(
                base_url='http://localhost:11434/v1',
                api_key='ollama'  # OllamaëŠ” API í‚¤ ë¶ˆí•„ìš”
            )
        
        print(f"  ğŸ¤– LLM: {llm_provider}/{llm_model}")
        print("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n")
    
    def retrieve(self, query, top_k=5):
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            List of (text, score, metadata)
        """
        # ì¿¼ë¦¬ í™•ì¥: íŠ¹ì • í‚¤ì›Œë“œ ê°•í™”
        expanded_query = query
        
        # ì‹ë‹¹ëª… ë§¤í•‘ (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
        restaurant_keywords = {
            'ë¶„ì‹ë‹¹': 'ë¶„ì‹ë‹¹ ì¼í’ˆìš”ë¦¬',
            'êµì§ì›ì‹ë‹¹': 'êµì§ì›ì‹ë‹¹ ì •ì‹',
            'ì‹ í‰ìº í¼ìŠ¤ì‹ë‹¹': 'ì‹ í‰ìº í¼ìŠ¤ì‹ë‹¹',
            'í‘¸ë¦„ê´€': 'í‘¸ë¦„ê´€ ìƒí™œê´€ ì‹ë‹¹',
            'ì˜¤ë¦„ê´€': 'ì˜¤ë¦„ê´€ ìƒí™œê´€ ì‹ë‹¹'
        }
        
        for keyword, expansion in restaurant_keywords.items():
            if keyword in query:
                expanded_query = f"{query} {expansion}"
                break
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_vector = self.retriever.encode(expanded_query, normalize_embeddings=True).tolist()
        
        # Qdrant ê²€ìƒ‰ (ë” ë§ì´ ê²€ìƒ‰ í›„ í•„í„°ë§)
        search_result = self.qdrant_client.search(
            collection_name=self.collection_name,
            query_vector=query_vector,
            limit=top_k * 2  # 2ë°° ê²€ìƒ‰ í›„ ì¬ìˆœìœ„í™”
        )
        
        # ê²°ê³¼ í¬ë§·íŒ… ë° ì¬ìˆœìœ„í™”
        results = []
        for hit in search_result:
            score = hit.score
            title = hit.payload.get('title', '')
            
            # ì œëª© ì¼ì¹˜ë„ì— ë”°ë¥¸ ì ìˆ˜ ë¶€ìŠ¤íŠ¸
            query_lower = query.lower()
            title_lower = title.lower()
            
            # ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ì ìˆ˜ ì¦ê°€
            if 'ë¶„ì‹ë‹¹' in query_lower and 'ë¶„ì‹ë‹¹' in title_lower:
                score *= 1.3
            elif 'êµì§ì›ì‹ë‹¹' in query_lower and 'êµì§ì›ì‹ë‹¹' in title_lower:
                score *= 1.3
            elif 'í•™ìƒì‹ë‹¹' in query_lower and 'í•™ìƒì‹ë‹¹' in title_lower:
                score *= 1.3
            elif 'í•™ì‚¬ì¼ì •' in query_lower and 'í•™ì‚¬ì¼ì •' in title_lower:
                score *= 1.4  # í•™ì‚¬ì¼ì •ì€ ë” ë†’ì€ ë¶€ìŠ¤íŠ¸
            elif ('ì¼ì •' in query_lower or 'í•™ì‚¬' in query_lower) and 'í•™ì‚¬ì¼ì •' in title_lower:
                score *= 1.3
            elif 'í‘¸ë¦„ê´€' in query_lower and 'í‘¸ë¦„ê´€' in title_lower:
                score *= 1.3
            elif 'ì˜¤ë¦„ê´€' in query_lower and 'ì˜¤ë¦„ê´€' in title_lower:
                score *= 1.3
            elif 'ì‹ í‰' in query_lower and 'ì‹ í‰' in title_lower:
                score *= 1.3
            
            results.append({
                'text': hit.payload.get('text', ''),
                'score': score,  # ì¬ì¡°ì •ëœ ì ìˆ˜
                'original_score': hit.score,  # ì›ë³¸ ì ìˆ˜
                'chunk_id': hit.payload.get('chunk_id', ''),
                'title': title,
                'url': hit.payload.get('url', '')
            })
        
        # ì ìˆ˜ë¡œ ì¬ì •ë ¬
        results.sort(key=lambda x: x['score'], reverse=True)
        
        # Top-Kë§Œ ë°˜í™˜
        return results[:top_k]
    
    def generate(self, query, contexts, stream=False):
        """
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLM ë‹µë³€ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            contexts: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
            
        Returns:
            LLM ìƒì„± ë‹µë³€
        """
        # í˜„ì¬ ë‚ ì§œ ë° ìš”ì¼ ì •ë³´ (í•œêµ­ ì‹œê°„)
        from datetime import datetime
        import locale
        import pytz
        
        try:
            locale.setlocale(locale.LC_TIME, 'ko_KR.UTF-8')
        except:
            pass
        
        # í•œêµ­ ì‹œê°„ëŒ€ (KST, UTC+9)
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
        
        # í•œêµ­ì–´ ìš”ì¼ ë§¤í•‘
        weekday_kr = {
            'Monday': 'ì›”ìš”ì¼',
            'Tuesday': 'í™”ìš”ì¼', 
            'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼',
            'Friday': 'ê¸ˆìš”ì¼',
            'Saturday': 'í† ìš”ì¼',
            'Sunday': 'ì¼ìš”ì¼'
        }
        weekday_en = now.strftime('%A')
        weekday = weekday_kr.get(weekday_en, weekday_en)
        
        today_info = f"{now.strftime('%Yë…„ %mì›” %dì¼')} ({weekday})"
        
        # ë‹¤ìŒì£¼ ì›”ìš”ì¼ ê³„ì‚°
        from datetime import timedelta
        days_until_next_monday = (7 - now.weekday()) % 7
        if days_until_next_monday == 0:
            days_until_next_monday = 7
        next_monday = now + timedelta(days=days_until_next_monday)
        next_monday_info = f"{next_monday.strftime('%Yë…„ %mì›” %dì¼')} ({weekday_kr.get(next_monday.strftime('%A'), next_monday.strftime('%A'))})"
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„± (ì¶œì²˜ ì •ë³´ í¬í•¨)
        context_str = "\n\n".join([
            f"[ë¬¸ì„œ {i+1}]\nì œëª©: {ctx.get('title', 'ì œëª©ì—†ìŒ')}\në‚´ìš©: {ctx['text']}" 
            for i, ctx in enumerate(contexts)
        ])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê°œì„ ëœ ë²„ì „)
        system_prompt = f"""ë‹¹ì‹ ì€ ê¸ˆì˜¤ê³µê³¼ëŒ€í•™êµ í•™ìƒë“¤ì„ ë•ëŠ” ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ Kit_Botì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•˜ë©° ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**í˜„ì¬ ë‚ ì§œ**: {today_info} (í˜„ì¬ ìš”ì¼ ì½”ë“œ: {now.weekday()}, 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
**ë‹¤ìŒì£¼ ì›”ìš”ì¼**: {next_monday_info}
- ì§ˆë¬¸ì— "ì˜¤ëŠ˜", "ì´ë²ˆì£¼" ë“±ì˜ ì‹œê°„ í‘œí˜„ì´ ìˆìœ¼ë©´ ìœ„ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- "ë‹¤ìŒì£¼ ì›”ìš”ì¼"ì€ {next_monday_info}ì…ë‹ˆë‹¤
- ìš”ì¼ë³„ ì •ë³´ê°€ í•„ìš”í•˜ë©´ í˜„ì¬ ìš”ì¼ì„ ì°¸ê³ í•˜ì„¸ìš”

ë‹µë³€ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. **ì •í™•ì„±**: ì œê³µëœ ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. **ì™„ì„±ë„**: ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ê´€ë ¨ëœ ëª¨ë“  ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”
3. **êµ¬ì¡°í™”**: ë³µì¡í•œ ì •ë³´ëŠ” ë²ˆí˜¸ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”
4. **ì‹¤ìš©ì„±**: 
   - ì ˆì°¨ë‚˜ ë°©ë²•ì„ ì„¤ëª…í•  ë•ŒëŠ” ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì•ˆë‚´í•˜ì„¸ìš”
   - ë‚ ì§œ, ì‹œê°„, ê¸ˆì•¡, ì—°ë½ì²˜ ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ì œê³µí•˜ì„¸ìš”
   - ê´€ë ¨ URLì´ë‚˜ ì—°ë½ì²˜ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
5. **í•œê³„ ì¸ì •**: ë¬¸ì„œì— ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ì œê³µëœ ì •ë³´ë¡œëŠ” [êµ¬ì²´ì  ë¶€ë¶„]ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë°íˆì„¸ìš”

ë‹µë³€ í˜•ì‹:
- ì§ì ‘ì ì´ê³  ëª…í™•í•œ ë‹µë³€ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- í•„ìš”ì‹œ ì„¸ë¶€ ì‚¬í•­ì„ ì¶”ê°€ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- í•™ìƒ ì…ì¥ì—ì„œ ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•ˆë‚´í•˜ì„¸ìš”"""

        user_prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ìƒì„¸í•˜ê³  ì™„ì „í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

<ì°¸ê³  ë¬¸ì„œ>
{context_str}
</ì°¸ê³  ë¬¸ì„œ>

<í•™ìƒ ì§ˆë¬¸>
{query}
</í•™ìƒ ì§ˆë¬¸>

**ì¤‘ìš” ê°€ì´ë“œ**:
- **ì‹ë‹¹ ë©”ë‰´** ì§ˆë¬¸ì˜ ê²½ìš°: ë¬¸ì„œì—ì„œ ìš”ì¼ë³„ ë©”ë‰´ë¥¼ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
  ì˜ˆ: "[ ì›”(11.03) | í™”(11.04) | ... ]" í˜•ì‹ì—ì„œ í˜„ì¬ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ìš”ì¼ì˜ ë©”ë‰´ë§Œ ì¶”ì¶œ
  ê° " | " êµ¬ë¶„ìë¡œ ìš”ì¼ì´ ë‚˜ë‰˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤
- ë©”ë‰´ í•­ëª©ì€ ì‰¼í‘œë‚˜ ê³µë°± ì—†ì´ ë¶™ì–´ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì˜ë¯¸ ë‹¨ìœ„ë¡œ êµ¬ë¶„í•˜ì„¸ìš”
  ì˜ˆ: "ëˆì½”ì¸ ë¼ë©˜ìœ¡íšŒë¹„ë¹”ë°¥ë¼ë©´ë¥˜" â†’ "ëˆì½”ì¸ ë¼ë©˜, ìœ¡íšŒë¹„ë¹”ë°¥, ë¼ë©´ë¥˜"

- **í•™ì‚¬ì¼ì •** ì§ˆë¬¸ì˜ ê²½ìš°: ë¬¸ì„œ í˜•ì‹ì´ "ë²ˆí˜¸ ì œëª© ì‹œì‘ì¼ ì¢…ë£Œì¼ ë“±ë¡ì¼ ì¡°íšŒ" íŒ¨í„´ì…ë‹ˆë‹¤
  ì˜ˆ: "365 êµ°ë³µë¬´ ì¤‘ ì·¨ë“í•™ì  ë“± ì™¸ë¶€ê¸°ê´€ í•™ì  ì¸ì • ì‹ ì²­ 2025-10-01 2025-10-03 2024-11-27 0"
  â†’ ì œëª©: êµ°ë³µë¬´ ì¤‘ ì·¨ë“í•™ì  ë“± ì™¸ë¶€ê¸°ê´€ í•™ì  ì¸ì • ì‹ ì²­
  â†’ ê¸°ê°„: 2025-10-01 ~ 2025-10-03
- ë‚ ì§œë³„ë¡œ ì •ë¦¬í•˜ì—¬ ì¼ì •ì„ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì„¸ìš”
- ê°™ì€ ë‚ ì§œì˜ ì¼ì •ì´ ì—¬ëŸ¬ ê°œë©´ ëª¨ë‘ ë‚˜ì—´í•˜ì„¸ìš”

ë‹µë³€:"""
        
        # LLM í˜¸ì¶œ
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        if stream:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=messages,
                stream=True,
                temperature=0.3,
                max_tokens=800  # ì¦ê°€: ë” ìƒì„¸í•œ ë‹µë³€
            )
            return response
        else:
            # ì¼ë°˜ ëª¨ë“œ
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=messages,
                temperature=0.3,
                max_tokens=800  # ì¦ê°€: ë” ìƒì„¸í•œ ë‹µë³€
            )
            return response.choices[0].message.content
    
    def query(self, question, top_k=5, verbose=True):  # Top-3 â†’ Top-5ë¡œ ì¦ê°€
        """
        ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’ 5ë¡œ ì¦ê°€)
            verbose: ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            ë‹µë³€ ë° ê²€ìƒ‰ ê²°ê³¼
        """
        if verbose:
            print(f"\n{'='*80}")
            print(f"â“ ì§ˆë¬¸: {question}")
            print(f"{'='*80}\n")
        
        # 1. ê²€ìƒ‰
        if verbose:
            print(f"ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘... (Top-{top_k})")
        
        contexts = self.retrieve(question, top_k=top_k)
        
        if verbose:
            print(f"\nğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ:")
            for i, ctx in enumerate(contexts):
                print(f"\n[ë¬¸ì„œ {i+1}] (ìœ ì‚¬ë„: {ctx['score']:.3f})")
                print(f"ì œëª©: {ctx['title']}")
                print(f"ë‚´ìš©: {ctx['text'][:200]}...")
                if ctx['url']:
                    print(f"URL: {ctx['url']}")
        
        # 2. ë‹µë³€ ìƒì„±
        if verbose:
            print(f"\nğŸ¤– LLM ë‹µë³€ ìƒì„± ì¤‘...")
        
        answer = self.generate(question, contexts)
        
        if verbose:
            print(f"\n{'='*80}")
            print(f"ğŸ’¬ ë‹µë³€:")
            print(f"{'='*80}")
            print(answer)
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            print(f"\n{'='*80}")
            print(f"ğŸ“ ì¶œì²˜:")
            print(f"{'='*80}")
            unique_sources = {}
            for ctx in contexts:
                url = ctx.get('url', '')
                title = ctx.get('title', '')
                if url and url not in unique_sources:
                    unique_sources[url] = title
            
            for i, (url, title) in enumerate(unique_sources.items(), 1):
                print(f"{i}. {title}")
                print(f"   {url}")
            print(f"{'='*80}\n")
        
        return {
            'question': question,
            'answer': answer,
            'contexts': contexts
        }

def main():
    """ëŒ€í™”í˜• RAG ë°ëª¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ê¸ˆì˜¤ê³µëŒ€ RAG ì±—ë´‡')
    parser.add_argument('--provider', default='openai', choices=['openai', 'ollama'],
                        help='LLM ì œê³µì')
    parser.add_argument('--model', default='gpt-4o-mini',
                        help='LLM ëª¨ë¸ ì´ë¦„')
    parser.add_argument('--top-k', type=int, default=5,  # ê¸°ë³¸ê°’ 3 â†’ 5
                        help='ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜')
    parser.add_argument('--query', type=str, default=None,
                        help='ë‹¨ì¼ ì§ˆë¬¸ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ)')
    args = parser.parse_args()
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = RAGSystem(
        llm_provider=args.provider,
        llm_model=args.model
    )
    
    if args.query:
        # ë‹¨ì¼ ì§ˆë¬¸ ëª¨ë“œ
        rag.query(args.query, top_k=args.top_k)
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        print("\n" + "="*80)
        print("ğŸ“ ê¸ˆì˜¤ê³µëŒ€ AI ì–´ì‹œìŠ¤í„´íŠ¸")
        print("="*80)
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')\n")
        
        while True:
            try:
                question = input("â“ ì§ˆë¬¸: ").strip()
                
                if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if not question:
                    continue
                
                rag.query(question, top_k=args.top_k)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")

if __name__ == "__main__":
    main()
