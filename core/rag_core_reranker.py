# rag_core_reranker.py - ë¦¬ëž­ì»¤ ë²„ì „
import os
import json
from typing import List, Dict, Any, Tuple, Optional
from dotenv import load_dotenv
from datetime import datetime
import pytz
from sentence_transformers import SentenceTransformer, CrossEncoder
from qdrant_client import QdrantClient
from qdrant_client.http import models as qm
from openai import OpenAI

from core.router import classify_query_intent

load_dotenv()

# --------------------
# í™˜ê²½ ì„¤ì •
# --------------------
QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION", "kitbot_docs_bge")
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "BAAI/bge-m3")
OPENAI_MODEL = os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini")

# --------------------
# ì‹±ê¸€í†¤
# --------------------
_qdrant_client: QdrantClient | None = None
_embed_model: SentenceTransformer | None = None
_llm_client: OpenAI | None = None
_reranker_model: CrossEncoder | None = None


def get_qdrant_client() -> QdrantClient:
    global _qdrant_client
    if _qdrant_client is None:
        _qdrant_client = QdrantClient(url=QDRANT_URL)
    return _qdrant_client


def get_embed_model() -> SentenceTransformer:
    global _embed_model
    if _embed_model is None:
        print("â³ ìž„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...", EMBED_MODEL_NAME)
        _embed_model = SentenceTransformer(EMBED_MODEL_NAME)
    return _embed_model


def get_llm_client() -> OpenAI:
    global _llm_client
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    if _llm_client is None:
        _llm_client = OpenAI(api_key=api_key)
    return _llm_client


def get_reranker_model() -> CrossEncoder:
    """BGE-reranker-v2-m3 ëª¨ë¸ ë¡œë“œ"""
    global _reranker_model
    if _reranker_model is None:
        print("â³ ë¦¬ëž­ì»¤ ëª¨ë¸ ë¡œë”© ì¤‘... BAAI/bge-reranker-v2-m3")
        _reranker_model = CrossEncoder('BAAI/bge-reranker-v2-m3', max_length=512)
    return _reranker_model


# --------------------
# ë¦¬ëž­ì»¤ ê¸°ë°˜ ê²€ìƒ‰
# --------------------
def search_with_reranker(query: str, top_k: int = 5, initial_k: int = 15) -> List[Any]:
    """
    1) ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ initial_kê°œ ê°€ì ¸ì˜¤ê¸°
    2) CrossEncoder ë¦¬ëž­ì»¤ë¡œ ìž¬ì •ë ¬
    3) ìƒìœ„ top_kê°œ ë°˜í™˜
    """
    client = get_qdrant_client()
    model = get_embed_model()
    reranker = get_reranker_model()

    # 1. ì‹œë§¨í‹± ê²€ìƒ‰ (ë” ë§Žì´ ê°€ì ¸ì˜¤ê¸°)
    query_vec = model.encode(query).tolist()
    
    res = client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vec,
        limit=initial_k,
        with_payload=True,
    )

    candidates = res.points

    if not candidates:
        return []

    # 2. ë¦¬ëž­ì»¤ ì ìš©
    # CrossEncoderëŠ” (query, document) ìŒì˜ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ì§ì ‘ ê³„ì‚°
    pairs = []
    for point in candidates:
        payload = point.payload or {}
        text = (
            payload.get("chunk_text") or 
            payload.get("text") or 
            payload.get("main_text") or 
            payload.get("content") or ""
        )
        pairs.append([query, text[:512]])  # ìµœëŒ€ 512ìžë¡œ ì œí•œ
    
    # ë¦¬ëž­í‚¹ ì ìˆ˜ ê³„ì‚°
    scores = reranker.predict(pairs)
    
    # 3. ì ìˆ˜ ê¸°ì¤€ ìž¬ì •ë ¬
    scored_points = list(zip(candidates, scores))
    scored_points.sort(key=lambda x: x[1], reverse=True)
    
    # 4. ìƒìœ„ top_kê°œ ì„ íƒ ë° ì ìˆ˜ ì—…ë°ì´íŠ¸
    final_results = []
    for point, score in scored_points[:top_k]:
        point.score = float(score)  # ë¦¬ëž­ì»¤ ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
        final_results.append(point)
    
    print(f"   ðŸ” ë¦¬ëž­ì»¤ ê²€ìƒ‰: ì´ˆê¸° {len(candidates)}ê°œ â†’ ë¦¬ëž­í‚¹ â†’ ìµœì¢… {len(final_results)}ê°œ")
    
    return final_results


# --------------------
# ê²€ìƒ‰ ë‹¨ê³„ (APIìš©)
# --------------------
def retrieve_points(query: str, top_k: int = 5):
    """ë¦¬ëž­ì»¤ ê²€ìƒ‰ ì‚¬ìš©"""
    return search_with_reranker(query, top_k, initial_k=15)


# --------------------
# ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ ë³€í™˜
# --------------------
def build_context_blocks(points) -> str:
    blocks = []

    for i, p in enumerate(points):
        payload = p.payload or {}

        text = (
            payload.get("chunk_text")
            or payload.get("text")
            or payload.get("main_text")
            or payload.get("content")
            or ""
        )

        if not text.strip():
            continue

        meta = (
            f"[{i+1}] site={payload.get('site')} | "
            f"board={payload.get('board_name')} | "
            f"title={payload.get('title')} | "
            f"date={payload.get('created_at')} | "
            f"url={payload.get('url')}"
        )

        block = meta + "\n" + text
        blocks.append(block)

    return "\n\n---\n\n".join(blocks)


# --------------------
# LLM í˜¸ì¶œ
# --------------------
def call_llm(system_msg: str, user_msg: str, model: str = None) -> str:
    if model is None:
        model = OPENAI_MODEL

    client = get_llm_client()
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg},
        ],
        temperature=0.7,
        max_tokens=1000,
    )
    return resp.choices[0].message.content


# --------------------
# ì¼ì • ì •ë³´ ì¶”ì¶œ
# --------------------
def extract_schedule_info(answer: str) -> Dict[str, Optional[str]]:
    import re
    
    result = {
        "scheduleTitle": None,
        "startDate": None,
        "endDate": None
    }
    
    date_pattern = r'\d{4}[-ë…„]\s?\d{1,2}[-ì›”]\s?\d{1,2}ì¼?'
    dates = re.findall(date_pattern, answer)
    
    if dates:
        result["startDate"] = dates[0].replace('ë…„', '-').replace('ì›”', '-').replace('ì¼', '').replace(' ', '')
        if len(dates) > 1:
            result["endDate"] = dates[1].replace('ë…„', '-').replace('ì›”', '-').replace('ì¼', '').replace(' ', '')
    
    lines = answer.split('\n')
    if lines:
        first_line = lines[0].strip()
        if len(first_line) > 0 and len(first_line) < 100:
            result["scheduleTitle"] = first_line
    
    return result


# --------------------
# RAG with Sources
# --------------------
def rag_with_sources(query: str, top_k: int = 5):
    from core.router import classify_query_intent
    intent = classify_query_intent(query)

    if intent == "chitchat":
        system_msg = "ë„ˆëŠ” ê¸ˆì˜¤ê³µëŒ€ í•™ìƒë“¤ì„ ë•ëŠ” ì¹œì ˆí•œ AI ì±—ë´‡ 'KIT-BOT'ì´ì•¼. í•™ìƒì—ê²Œ ë‹¤ì •í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜."
        answer = call_llm(system_msg, query)
        return answer, [], {"scheduleTitle": None, "startDate": None, "endDate": None}
    
    points = retrieve_points(query, top_k)
    
    SIMILARITY_THRESHOLD = 0.4

    if not points or points[0].score < SIMILARITY_THRESHOLD:
        print(f"   ðŸ“‰ ê²€ìƒ‰ ì ìˆ˜ ë¯¸ë‹¬: {points[0].score if points else 0} < {SIMILARITY_THRESHOLD}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•™êµ ì •ë³´ì™€ ê´€ë ¨ì´ ì—†ê±°ë‚˜, í•´ë‹¹ ë‚´ìš©ì„ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", [], {"scheduleTitle": None, "startDate": None, "endDate": None}

    context_text = build_context_blocks(points)
    
    now = datetime.now(pytz.timezone('Asia/Seoul'))
    today_str = now.strftime("%Yë…„ %mì›” %dì¼")
    current_year = now.year

    system_msg = (
        f"ë‹¹ì‹ ì€ êµ­ë¦½ê¸ˆì˜¤ê³µê³¼ëŒ€í•™êµ í•™ìƒë“¤ì„ ë•ëŠ” **ë‹¤ì •í•˜ê³  ì¹œì ˆí•œ AI ë©˜í†  'KIT-BOT'**ìž…ë‹ˆë‹¤.\n"
        f"í˜„ìž¬ ì‹œê°ì€ **{today_str}**ì´ì—ìš”.\n\n"
        "í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ [ê²€ìƒ‰ëœ ë¬¸ì„œ]ë¥¼ ê¼¼ê¼¼ížˆ í™•ì¸í•´ì„œ, **ë”°ëœ»í•˜ê³  ìƒëƒ¥í•œ ë§íˆ¬(í•´ìš”ì²´)**ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\n"
        
        "## 1. ë‹µë³€ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨ (ê°€ìž¥ ì¤‘ìš”!)\n"
        "   - ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ [ê²€ìƒ‰ëœ ë¬¸ì„œ]ì— **ëª…í™•í•˜ê²Œ í¬í•¨ë˜ì–´ ìžˆì§€ ì•Šë‹¤ë©´**, ì–µì§€ë¡œ ì§€ì–´ë‚´ê±°ë‚˜ ë¹„ìŠ·í•œ ë‚´ìš©ì„ ë¬´ë¦¬í•˜ê²Œ ì—°ê²°í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "   - ì •ë³´ê°€ ì—†ì„ ë•ŒëŠ” **'ì£„ì†¡í•˜ì§€ë§Œ, í•´ë‹¹ ë‚´ìš©ì€ í•™êµ ê³µì§€ë‚˜ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ê°€ ì—†ë„¤ìš” ðŸ˜¥. í˜¹ì‹œ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì‹œê² ì–´ìš”?'**ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\n"

        "## 2. ì„¼ìŠ¤ ìžˆëŠ” ì‹œê°„ í™•ì¸ (Time Awareness)\n"
        f"   - ë¬¸ì„œ ë‚´ìš©ì´ **ì˜¬í•´({current_year}ë…„)** ê²ƒì¸ì§€ ê¼­ í™•ì¸í•´ ì£¼ì„¸ìš”.\n"
        f"   - ë§Œì•½ ì˜¬í•´ ìµœì‹  ê³µì§€ê°€ ì—†ê³  ìž‘ë…„ ìžë£Œë§Œ ìžˆë‹¤ë©´, **'ì•„ì‰½ê²Œë„ ì•„ì§ {current_year}ë…„ë„ ê³µì§€ëŠ” ì˜¬ë¼ì˜¤ì§€ ì•Šì•˜ì–´ìš”.'**ë¼ê³  ì•ˆë‚´í•´ ì£¼ì„¸ìš”.\n\n"
        
        "## 3. ë³´ê¸° íŽ¸í•˜ê³  ì¹œì ˆí•œ ì„¤ëª…\n"
        "   - ë‚ ì§œ, ìž¥ì†Œ, ì „í™”ë²ˆí˜¸ ê°™ì€ í•µì‹¬ ì •ë³´ëŠ” **êµµê²Œ(**)** í‘œì‹œí•´ì„œ ëˆˆì— ìž˜ ë„ê²Œ í•´ì£¼ì„¸ìš”.\n"
        "   - ë³µìž¡í•œ ë‚´ìš©ì€ **ë¦¬ìŠ¤íŠ¸**ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ ì£¼ëŠ” ì„¼ìŠ¤ë¥¼ ë°œíœ˜í•´ ì£¼ì„¸ìš”.\n\n"
        
        "## 4. ë§ˆë¬´ë¦¬\n"
        "   - ë‹µë³€ ëì—ëŠ” **'ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”!'** ë©˜íŠ¸ë¥¼ ë§ë¶™ì—¬ ì£¼ì„¸ìš”.\n"
    )

    user_msg = (
        f"ì§ˆë¬¸: {query}\n\n"
        f"--- ê²€ìƒ‰ëœ ë¬¸ì„œ ì‹œìž‘ ---\n"
        f"{context_text}\n"
        f"--- ê²€ìƒ‰ëœ ë¬¸ì„œ ë ---\n\n"
        f"ìœ„ ë¬¸ì„œë¥¼ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜."
    )
    
    answer = call_llm(system_msg, user_msg)

    schedule_data = {"scheduleTitle": None, "startDate": None, "endDate": None}

    negative_keywords = [
        "ì£„ì†¡í•˜ì§€ë§Œ", "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"
    ]
    
    if any(neg in answer for neg in negative_keywords):
        final_sources = []
    else:
        final_sources = []
        for p in points:
            payload = p.payload or {}
            final_sources.append({
                "title": payload.get("title"),
                "url": payload.get("url"),
                "text": payload.get("text")
            })

    if final_sources and (intent == "schedule" or "202" in answer):
        extracted = extract_schedule_info(answer)
        if extracted.get("startDate"):
            schedule_data = extracted

    return answer, final_sources, schedule_data


def generate_answer(query: str, top_k: int = 5) -> str:
    answer, _, _ = rag_with_sources(query, top_k)
    return answer
