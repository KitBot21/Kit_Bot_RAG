#!/usr/bin/env python3
"""
BM25 Sparse Vector ê²€ìƒ‰ í‰ê°€
"""
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent))
from create_sparse_vectors import BM25Vectorizer

PROJECT_ROOT = Path(__file__).resolve().parents[1]

def sparse_search(query_vec, corpus_vecs, top_k=5):
    """Sparse vector ê¸°ë°˜ ê²€ìƒ‰ (ë‚´ì  ê³„ì‚°)"""
    scores = []
    
    for doc_vec in corpus_vecs:
        # ë‚´ì  ê³„ì‚°
        score = 0.0
        for idx, val in query_vec.items():
            if idx in doc_vec:
                score += val * doc_vec[idx]
        scores.append(score)
    
    # Top-K ì¸ë±ìŠ¤ ë°˜í™˜
    scores = np.array(scores)
    top_indices = np.argsort(scores)[::-1][:top_k]
    return top_indices, scores[top_indices]

def evaluate_sparse():
    print("=" * 70)
    print("ğŸ” BM25 Sparse Vector ê²€ìƒ‰ í‰ê°€")
    print("=" * 70)
    
    # Ground truth ë¡œë“œ
    gt_df = pd.read_csv(PROJECT_ROOT / 'data' / 'ground_truth.csv')
    queries = gt_df['query'].tolist()
    correct_ids = gt_df['chunk_id'].tolist()
    
    # Corpus ë¡œë“œ
    corpus_df = pd.read_csv(PROJECT_ROOT / 'data' / 'corpus_with_sources.csv')
    chunk_ids = corpus_df['chunk_id'].tolist()
    
    # BM25 ë²¡í„°í™”ê¸° ë° sparse vectors ë¡œë“œ
    with open(PROJECT_ROOT / 'embeddings' / 'bm25_vectorizer.pkl', 'rb') as f:
        vectorizer = pickle.load(f)
    
    with open(PROJECT_ROOT / 'embeddings' / 'bm25_sparse_vectors.pkl', 'rb') as f:
        corpus_vecs = pickle.load(f)
    
    print(f"\nğŸ“Š ë°ì´í„° ì •ë³´")
    print(f"  ì¿¼ë¦¬: {len(queries)}ê°œ")
    print(f"  ì½”í¼ìŠ¤: {len(corpus_vecs)}ê°œ ë¬¸ì„œ")
    print(f"  ì–´íœ˜: {len(vectorizer.vocab):,}ê°œ ë‹¨ì–´")
    
    # í‰ê°€
    top1_correct = 0
    top5_correct = 0
    mrr_sum = 0
    
    print(f"\nğŸ” ê²€ìƒ‰ ì‹œì‘...")
    
    for i, (query, correct_id) in enumerate(zip(queries, correct_ids)):
        # ì¿¼ë¦¬ ë²¡í„°í™”
        query_vec = vectorizer.transform_query(query)
        
        # ê²€ìƒ‰
        top_indices, scores = sparse_search(query_vec, corpus_vecs, top_k=5)
        
        # ì˜ˆì¸¡ëœ chunk_id
        pred_ids = [chunk_ids[idx] for idx in top_indices]
        
        # Top-1, Top-5 ì •í™•ë„
        if pred_ids[0] == correct_id:
            top1_correct += 1
            top5_correct += 1
            mrr_sum += 1.0
        elif correct_id in pred_ids:
            top5_correct += 1
            rank = pred_ids.index(correct_id) + 1
            mrr_sum += 1.0 / rank
        
        # ê²°ê³¼ ì¶œë ¥ (ë§¤ 10ê°œë§ˆë‹¤)
        if (i + 1) % 10 == 0 or correct_id in pred_ids[:5]:
            status = "âœ…" if correct_id in pred_ids else "âŒ"
            print(f"{status} Query {i+1}: {query}")
            if correct_id in pred_ids:
                rank = pred_ids.index(correct_id) + 1
                print(f"   ì •ë‹µ: {correct_id} (ìˆœìœ„: {rank})")
            print(f"   Top-5: {pred_ids}")
    
    # ìµœì¢… ê²°ê³¼
    top1_acc = top1_correct / len(queries)
    top5_acc = top5_correct / len(queries)
    mrr = mrr_sum / len(queries)
    
    print(f"\n" + "=" * 70)
    print(f"ğŸ“Š í‰ê°€ ê²°ê³¼ - BM25 Sparse Search")
    print("=" * 70)
    print(f"Top-1 Accuracy: {top1_acc:.4f} ({top1_correct}/{len(queries)})")
    print(f"Top-5 Accuracy: {top5_acc:.4f} ({top5_correct}/{len(queries)})")
    print(f"MRR:            {mrr:.4f}")
    print("=" * 70)
    
    return {
        'top1': top1_acc,
        'top5': top5_acc,
        'mrr': mrr
    }

if __name__ == "__main__":
    evaluate_sparse()
