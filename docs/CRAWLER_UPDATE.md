# ğŸ•·ï¸ í¬ë¡¤ëŸ¬ ì—…ë°ì´íŠ¸ ê°€ì´ë“œ - ìµœê·¼ 5ë…„ ë°ì´í„° ìˆ˜ì§‘

## ğŸ“‹ í˜„ì¬ í¬ë¡¤ëŸ¬ ë¶„ì„

âœ… **ì˜ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!**
- Sitemap ê¸°ë°˜ í¬ë¡¤ë§
- ì„¹ì…˜ë³„ í•„í„°ë§ (`ko`, `bus`, `dorm`)
- ë¡œê·¸ì¸ í˜ì´ì§€ ì°¨ë‹¨
- ì²¨ë¶€íŒŒì¼ ì •ì±… ê´€ë¦¬
- ì¤‘ë‹¨/ì¬ê°œ ê¸°ëŠ¥

## ğŸ¯ ìµœê·¼ 5ë…„ ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ë„ë¡ ê°œì„ 

### ë°©ë²• 1: Sitemap lastmod í•„í„°ë§ (ê¶Œì¥) â­

`crawler/core/sitemap.py` ìˆ˜ì •:

```python
from datetime import datetime, timedelta

# 5ë…„ ì „ ë‚ ì§œ ê³„ì‚°
CUTOFF_DATE = (datetime.now() - timedelta(days=5*365)).strftime("%Y-%m-%d")

def seed_from_sitemaps(sitemap_index, headers, timeout, allow_sections=None):
    """Sitemapì—ì„œ ìµœê·¼ 5ë…„ URLë§Œ ìˆ˜ì§‘"""
    lastmod_map = {}
    
    for url, lastmod in _extract_urls_from_sitemap(sitemap_index, headers, timeout):
        # lastmod í•„í„°ë§
        if lastmod and lastmod < CUTOFF_DATE:
            continue  # 5ë…„ ì´ì „ í˜ì´ì§€ëŠ” ê±´ë„ˆë›°ê¸°
        
        # ì„¹ì…˜ í•„í„°ë§
        if allow_sections:
            section = _extract_section(url)
            if section not in allow_sections:
                continue
        
        lastmod_map[url] = lastmod
    
    return lastmod_map
```

### ë°©ë²• 2: ì„¤ì • íŒŒì¼ì— ë‚ ì§œ í•„í„° ì¶”ê°€

`crawler/config.yml`:

```yaml
start_url: "https://www.kumoh.ac.kr/ko/index.do?sso=ok"
domain: "www.kumoh.ac.kr"
sitemap_index: "https://www.kumoh.ac.kr/sitemap_index.xml"

allow_sections: ["ko","bus","dorm"]
allowed_path_prefixes: ["/ko/", "/bus/notice.do","/dorm/"]

# === ìƒˆë¡œ ì¶”ê°€ ===
# ìµœê·¼ 5ë…„ ë°ì´í„°ë§Œ í¬ë¡¤ë§
date_filter:
  enabled: true
  cutoff_date: "2020-01-01"  # YYYY-MM-DD í˜•ì‹
  # ë˜ëŠ” ìƒëŒ€ ë‚ ì§œ
  # cutoff_days_ago: 1825  # 5ë…„ = 365 * 5

block_login_pages: true
attachment_policy: "blocklist"
attachment_allow_prefixes: []
attachment_block_prefixes: ["/cms/fileDownload.do"]

max_pages: 300000
request_timeout_sec: 10
request_sleep_sec: 0.7
user_agent: "KITBot (CSEcapstone, contact: cdh5113@naver.com)"

storage: "filesystem"
log_path: "../data/errors.log"

pii_policy:
  redact_email: true

deny_patterns:
  - "/login"
  - "/restaurant_menu_reg"
  - "/restaurant_reg"
```

### ë°©ë²• 3: ë¹ ë¥¸ ìŠ¤í¬ë¦½íŠ¸ (ê¸°ì¡´ í¬ë¡¤ëŸ¬ ìˆ˜ì • ì—†ì´)

`crawler/crawl_recent.sh`:

```bash
#!/bin/bash
# ìµœê·¼ 5ë…„ ë°ì´í„°ë§Œ í¬ë¡¤ë§í•˜ëŠ” ë˜í¼ ìŠ¤í¬ë¦½íŠ¸

cd "$(dirname "$0")"

echo "ğŸ•·ï¸  ìµœê·¼ 5ë…„ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘..."
echo ""

# 1. ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
python3 main.py config.yml

# 2. 5ë…„ ì´ì „ íŒŒì¼ ì œê±°
echo ""
echo "ğŸ“… 5ë…„ ì´ì „ ë°ì´í„° ì œê±° ì¤‘..."

CUTOFF_DATE="2020-01-01"
FIXTURES_DIR="../data/fixtures"

# 5ë…„ ì´ì „ íŒŒì¼ ì°¾ê¸°
OLD_FILES=$(find "$FIXTURES_DIR" -type f -not -newermt "$CUTOFF_DATE")
OLD_COUNT=$(echo "$OLD_FILES" | grep -c .)

if [ "$OLD_COUNT" -gt 0 ]; then
    echo "   ë°œê²¬ëœ ì˜¤ë˜ëœ íŒŒì¼: $OLD_COUNT ê°œ"
    echo "   ì œê±° ì¤‘..."
    find "$FIXTURES_DIR" -type f -not -newermt "$CUTOFF_DATE" -delete
    echo "   âœ… ì œê±° ì™„ë£Œ"
else
    echo "   â„¹ï¸  ì œê±°í•  íŒŒì¼ ì—†ìŒ"
fi

echo ""
echo "âœ… í¬ë¡¤ë§ ì™„ë£Œ!"
echo ""
echo "ğŸ“Š í†µê³„:"
find "$FIXTURES_DIR" -type f | wc -l | xargs echo "   íŒŒì¼ ìˆ˜:"
du -sh "$FIXTURES_DIR" | awk '{print "   ì´ í¬ê¸°: " $1}'
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ì˜µì…˜ A: ê¸°ì¡´ fixtures ì •ë¦¬ í›„ ì¬í¬ë¡¤ë§

```bash
cd ~/Kit_Bot_RAG/crawler

# 1. ê¸°ì¡´ ë°ì´í„° ë°±ì—…
mv ../data/fixtures ../data/fixtures_backup

# 2. ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ../data/fixtures

# 3. í¬ë¡¤ëŸ¬ ì‹¤í–‰
python3 main.py config.yml

# 4. ê²°ê³¼ í™•ì¸
ls -lh ../data/fixtures/ | head -20
find ../data/fixtures/ -type f | wc -l
```

### ì˜µì…˜ B: ìŠ¤ë§ˆíŠ¸ ì¬í¬ë¡¤ë§ (ìˆ˜ì •ëœ í˜ì´ì§€ë§Œ)

```bash
cd ~/Kit_Bot_RAG/crawler

# í¬ë¡¤ëŸ¬ëŠ” sitemapì˜ lastmodë¥¼ í™•ì¸í•˜ê³ 
# ë³€ê²½ëœ í˜ì´ì§€ë§Œ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ
python3 main.py config.yml
```

### ì˜µì…˜ C: íŠ¹ì • ì„¹ì…˜ë§Œ ì¬í¬ë¡¤ë§

```bash
# config.yml ì„ì‹œ ìˆ˜ì •
# allow_sections: ["dorm"]  # ê¸°ìˆ™ì‚¬ë§Œ

python3 main.py config.yml

# ì™„ë£Œ í›„ ì›ë˜ëŒ€ë¡œ
# allow_sections: ["ko","bus","dorm"]
```

---

## ğŸ“ í¬ë¡¤ëŸ¬ ê°œì„  ì½”ë“œ

ìƒˆ íŒŒì¼ ìƒì„±: `crawler/filters/date_filter.py`

```python
"""ë‚ ì§œ ê¸°ë°˜ URL í•„í„°ë§"""
from datetime import datetime, timedelta
from typing import Optional

class DateFilter:
    def __init__(self, cutoff_date: Optional[str] = None, cutoff_days_ago: Optional[int] = None):
        """
        Args:
            cutoff_date: "YYYY-MM-DD" í˜•ì‹ (ì˜ˆ: "2020-01-01")
            cutoff_days_ago: í˜„ì¬ë¶€í„° ë©°ì¹  ì „ê¹Œì§€ (ì˜ˆ: 1825 = 5ë…„)
        """
        if cutoff_date:
            self.cutoff = datetime.strptime(cutoff_date, "%Y-%m-%d")
        elif cutoff_days_ago:
            self.cutoff = datetime.now() - timedelta(days=cutoff_days_ago)
        else:
            # ê¸°ë³¸ê°’: 5ë…„
            self.cutoff = datetime.now() - timedelta(days=5*365)
    
    def is_recent(self, lastmod: Optional[str]) -> bool:
        """
        lastmodì´ cutoffë³´ë‹¤ ìµœê·¼ì¸ì§€ í™•ì¸
        
        Args:
            lastmod: "YYYY-MM-DD" ë˜ëŠ” "YYYY-MM-DDTHH:MM:SS" í˜•ì‹
        
        Returns:
            True if recent, False if old
        """
        if not lastmod:
            # lastmod ì •ë³´ ì—†ìœ¼ë©´ í—ˆìš© (ìµœì‹ ìœ¼ë¡œ ê°„ì£¼)
            return True
        
        try:
            # ë‚ ì§œ íŒŒì‹± (ì—¬ëŸ¬ í˜•ì‹ ì§€ì›)
            if 'T' in lastmod:
                date = datetime.fromisoformat(lastmod.replace('Z', '+00:00'))
            else:
                date = datetime.strptime(lastmod[:10], "%Y-%m-%d")
            
            return date >= self.cutoff
        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í—ˆìš©
            return True
```

`crawler/core/sitemap.py` ìˆ˜ì •:

```python
# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from filters.date_filter import DateFilter

def seed_from_sitemaps(sitemap_index, headers, timeout, allow_sections=None, date_filter=None):
    """
    Args:
        sitemap_index: sitemap index URL
        headers: HTTP headers
        timeout: request timeout
        allow_sections: í—ˆìš© ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        date_filter: DateFilter ì¸ìŠ¤í„´ìŠ¤ (ì˜µì…˜)
    """
    lastmod_map = {}
    
    # Sitemap íŒŒì‹± (ê¸°ì¡´ ë¡œì§)
    # ...
    
    for url, lastmod in all_urls:
        # ë‚ ì§œ í•„í„°ë§
        if date_filter and not date_filter.is_recent(lastmod):
            continue
        
        # ì„¹ì…˜ í•„í„°ë§ (ê¸°ì¡´ ë¡œì§)
        # ...
        
        lastmod_map[url] = lastmod
    
    return lastmod_map
```

`crawler/core/crawl.py` ìˆ˜ì •:

```python
# __init__ ë©”ì„œë“œì— ì¶”ê°€
from filters.date_filter import DateFilter

class Crawler:
    def __init__(self, settings: Loader):
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
        # ë‚ ì§œ í•„í„° ì„¤ì •
        self.date_filter = None
        if hasattr(settings, 'date_filter') and settings.date_filter.get('enabled'):
            cutoff_date = settings.date_filter.get('cutoff_date')
            cutoff_days = settings.date_filter.get('cutoff_days_ago')
            self.date_filter = DateFilter(cutoff_date, cutoff_days)
            self.logger.info(f"ë‚ ì§œ í•„í„° í™œì„±í™”: {self.date_filter.cutoff.strftime('%Y-%m-%d')} ì´í›„")
    
    def _seed_queue(self) -> deque[str]:
        lastmod_map = {}
        if self.s.sitemap_index:
            lastmod_map = seed_from_sitemaps(
                self.s.sitemap_index, 
                self.headers, 
                self.s.request_timeout_sec, 
                self.s.allow_sections,
                self.date_filter  # â† ì¶”ê°€
            )
        # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• (ì¶”ì²œ)

```bash
cd ~/Kit_Bot_RAG/crawler

# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
rm -rf ../data/fixtures/*

# ì¬í¬ë¡¤ë§
python3 main.py config.yml

# ì™„ë£Œ í›„ corpus ì¬ìƒì„±
cd ..
python3 create_filtered_corpus.py
```

### 2. ì½”ë“œ ìˆ˜ì • í›„ ì‹¤í–‰

```bash
cd ~/Kit_Bot_RAG/crawler

# 1. ë‚ ì§œ í•„í„° ì¶”ê°€
mkdir -p filters
# (ìœ„ì˜ date_filter.py ì½”ë“œë¥¼ filters/date_filter.pyì— ì €ì¥)

# 2. config.ymlì— date_filter ì„¤ì • ì¶”ê°€

# 3. ì‹¤í–‰
python3 main.py config.yml
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### Before (ì „ì²´ í¬ë¡¤ë§)
```
í¬ë¡¤ë§ ì™„ë£Œ: 2,847 í˜ì´ì§€
ìš©ëŸ‰: 185 MB
ì²˜ë¦¬ ì‹œê°„: 2-3ì‹œê°„
```

### After (ìµœê·¼ 5ë…„)
```
í¬ë¡¤ë§ ì™„ë£Œ: 800-1,200 í˜ì´ì§€
ìš©ëŸ‰: 50-80 MB
ì²˜ë¦¬ ì‹œê°„: 30-60ë¶„
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ê¸°ì¡´ fixtures ë°±ì—… ì™„ë£Œ
- [ ] í¬ë¡¤ëŸ¬ ì„¤ì • í™•ì¸ (config.yml)
- [ ] ë‚ ì§œ í•„í„° ì„¤ì • (ì˜µì…˜)
- [ ] í¬ë¡¤ë§ ì‹¤í–‰
- [ ] ê²°ê³¼ í™•ì¸ (íŒŒì¼ ìˆ˜, ìš©ëŸ‰)
- [ ] corpus ì¬ìƒì„±
- [ ] ì„ë² ë”© ì¬ìƒì„±
- [ ] RAG í…ŒìŠ¤íŠ¸

---

**ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**

1. **ê°„ë‹¨í•˜ê²Œ**: ê¸°ì¡´ fixtures ì‚­ì œ í›„ ì¬í¬ë¡¤ë§ (ì½”ë“œ ìˆ˜ì • ì—†ìŒ)
2. **ìŠ¤ë§ˆíŠ¸í•˜ê²Œ**: ë‚ ì§œ í•„í„° ì½”ë“œ ì¶”ê°€ í›„ ì¬í¬ë¡¤ë§
3. **ë‹¨ê³„ì ìœ¼ë¡œ**: ì¼ë¶€ ì„¹ì…˜ë§Œ ë¨¼ì € í…ŒìŠ¤íŠ¸

ì¶”ì²œ: **1ë²ˆ (ê°„ë‹¨í•˜ê²Œ)** - ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•©ë‹ˆë‹¤!
