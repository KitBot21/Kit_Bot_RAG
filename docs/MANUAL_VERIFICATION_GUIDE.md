# 수동 Ground Truth 검증 가이드

## 📌 왜 수동 검증이 필요한가?

현재 자동 생성된 ground truth는 **circular logic(순환 논리)** 문제가 있습니다:
- 같은 모델로 검색해서 Top-1을 정답으로 저장
- 같은 모델로 검색해서 정답 찾기
- 결과: 100% Recall (실제 품질과 무관)

**수동 검증**은 사람이 직접 검색 결과를 보고 정답 여부를 판단합니다.

---

## 🛠️ 도구 사용법

### 1️⃣ 빠른 테스트 (5개 쿼리)

```bash
python scripts/quick_verify_sample.py
```

**특징:**
- 5개 샘플 쿼리로 빠른 테스트
- 도구 사용법 익히기
- Top-3 결과만 표시

**예시 질문:**
- "2024년 2학기 통학버스 운행 노선표가 필요해요"
- "중소기업 취업연계 장학금 신청 방법을 알고 싶어요"
- "아름책마루 목요일 연장 운영시간이 어떻게 되나요"

---

### 2️⃣ 전체 검증 (70/31/30개 쿼리)

```bash
python scripts/manual_ground_truth_verification.py
```

**메뉴:**
1. Dev Set (70개) - 개발/튜닝용
2. Test Set (31개) - 최종 평가용
3. Manual Set (30개) - 사용자 작성 쿼리
4. 커스텀 파일

**입력 옵션:**
- `1-5`: 정답 번호 선택
- `n`: 정답 없음 (모두 관련 없음)
- `s`: 건너뛰기
- `q`: 종료 (진행상황 자동 저장)

**자동 저장:**
- 10개마다 자동 저장
- Ctrl+C 또는 `q`로 중단해도 진행상황 보존
- 재시작 시 이어서 진행 가능

---

## 📊 검증 프로세스

### 예시: 쿼리 검증

```
================================================================================
[1/70] 쿼리: 2024년 2학기 통학버스 운행 노선표가 필요해요
================================================================================

[1] 스코어: 0.6981
    제목: 대구통학버스 | 공지사항 | 공지사항
    내용: 2024학년도 2학기 대구통학버스 운행 안내...
    
[2] 스코어: 0.6568
    제목: 대구통학버스 | 공지사항 | 공지사항
    내용: 2022학년도 2학기 대구통학버스 운행 변경 안내...
    
[3] 스코어: 0.6567
    제목: 대구통학버스 | 공지사항 | 공지사항
    내용: 2024학년도 2학기 대구통학버스 운행일정 변경 알림...

정답 선택 (1-5, n=없음, s=건너뛰기, q=종료): 
```

**판단 기준:**
- ✅ **1번 선택**: 2024년 2학기 정보가 맞음
- ❌ **2번은 틀림**: 2022년 정보 (오래됨)
- ⚠️ **3번도 정답 가능**: 운영일정 변경 안내

→ **가장 정확한 정답 1개만 선택**

---

## 🎯 좋은 검증을 위한 팁

### 1. 명확한 판단 기준

**정답:**
- 질문에 직접적으로 답하는 내용
- 최신 정보 우선
- 구체적이고 완전한 답변

**정답 없음 (n):**
- Top-5 모두 관련 없음
- 질문과 다른 주제
- 너무 오래된 정보만 있음

### 2. 구체적인 질문 작성

❌ 나쁜 예: "통학버스 시간표"
- 너무 모호함
- 여러 학기 정보 모두 정답 가능

✅ 좋은 예: "2024년 2학기 통학버스 운행 노선표가 필요해요"
- 학기 특정
- 명확한 정답 1개

### 3. 시간 관리

- **한 번에 10-20개씩** 검증 (자동 저장됨)
- 피곤하면 중단 후 나중에 재개
- Dev Set (70개) → 약 30-40분 소요

---

## 📈 결과 분석

### 검증 완료 후

```bash
# 검증된 ground truth로 재평가
python scripts/evaluate_retrieval.py
```

**기대 성능:**
- **자동 생성**: Recall@3 90-100% (circular logic)
- **수동 검증**: Recall@3 70-85% (실제 성능)

**성능 하락은 정상입니다!**
- 자동 생성은 과대평가됨
- 수동 검증이 실제 품질을 반영

---

## 📝 출력 파일

| 파일명 | 내용 |
|--------|------|
| `ground_truth_dev_manual.csv` | Dev Set 수동 검증 |
| `ground_truth_test_manual.csv` | Test Set 수동 검증 |
| `ground_truth_manual_verified.csv` | Manual Set 수동 검증 |

**CSV 형식:**
```csv
query,document_name,rank,similarity
2024년 2학기 통학버스...,대구통학버스 | 공지사항,1,0.6981
이번 주 학생식당 메뉴...,NO_ANSWER,-1,0.0
```

---

## 🔄 재평가 워크플로우

```bash
# 1. 수동 검증
python scripts/manual_ground_truth_verification.py

# 2. 기존 파일 백업
cd data
mv ground_truth_dev.csv ground_truth_dev_auto.csv
mv ground_truth_dev_manual.csv ground_truth_dev.csv

# 3. 재평가
python scripts/evaluate_retrieval.py

# 4. 성능 비교
# - Auto (자동): Recall@3 90%+
# - Manual (수동): Recall@3 70-85%
# - Manual이 실제 성능!
```

---

## ❓ FAQ

### Q1. 여러 개가 정답일 때는?

→ **가장 좋은 답변 1개만** 선택
- 최신 정보
- 가장 구체적인 내용
- 가장 완전한 답변

### Q2. 정답이 5위 밖에 있다면?

→ `n` 입력 (정답 없음)
- Top-5에 없으면 검색 실패로 간주
- 나중에 쿼리 개선이 필요함을 의미

### Q3. 중단 후 재시작하면?

→ 자동으로 이어서 진행
- 10개마다 자동 저장
- 기존 파일 발견 시 "이어서 진행?" 물어봄

### Q4. 실수로 잘못 선택했다면?

→ 파일을 직접 수정하거나 다시 검증
```bash
# CSV 파일 열어서 수정
nano data/ground_truth_dev_manual.csv

# 또는 해당 쿼리만 다시 검증 (커스텀 파일 옵션)
```

---

## 📊 예상 결과

### 현재 자동 생성 (Circular Logic)
```
Dataset         R@1    R@3    R@5    R@10   MRR
Dev Set         23%    90%    99%    100%   0.58
Test Set        32%    97%    97%    100%   0.65
Manual Set      33%    93%    100%   100%   0.65
```

### 수동 검증 후 (실제 성능)
```
Dataset         R@1    R@3    R@5    R@10   MRR
Dev Set         20%    70%    85%    95%    0.45
Test Set        25%    75%    90%    95%    0.50
Manual Set      30%    80%    90%    95%    0.55
```

**해석:**
- Recall@3 70-80%: 매우 우수 ✅
- Recall@5 85-90%: 충분히 좋음 ✅
- MRR 0.45-0.55: 평균 2-3위에 정답 ✅

---

## 🎯 실행 예시

```bash
# 빠른 테스트 (5개 샘플)
$ python scripts/quick_verify_sample.py

# Dev Set 검증 (70개)
$ python scripts/manual_ground_truth_verification.py
선택 (1-4): 1

# 진행...
[1/70] 쿼리: ...
정답 선택: 1
✅ 1번 선택

[2/70] 쿼리: ...
정답 선택: n
❌ 정답 없음

# ... 10개 완료 시 자동 저장 ...

# 중단 (Ctrl+C 또는 q)
💾 진행상황 저장됨

# 재시작
$ python scripts/manual_ground_truth_verification.py
선택 (1-4): 1
⚠️  기존 검증 파일 발견
기존 결과를 이어서 진행할까요? (y/n): y
✅ 10개 이미 검증됨

# 11번부터 이어서 진행...
```

---

## ✅ 체크리스트

검증 전:
- [ ] 질문이 구체적인가?
- [ ] 모호한 질문은 없는가?
- [ ] 테스트 도구로 연습했는가?

검증 중:
- [ ] Top-5 결과를 꼼꼼히 읽는가?
- [ ] 최신 정보를 우선하는가?
- [ ] 피곤하면 중단하고 쉬는가?

검증 후:
- [ ] 파일이 저장되었는가?
- [ ] 재평가를 실행했는가?
- [ ] 성능 하락이 예상 범위인가?

---

## 📞 문제 해결

### 파일이 안 보인다면?
```bash
ls -lh data/ground_truth_*
```

### 검증 결과 확인
```bash
wc -l data/ground_truth_dev_manual.csv
# 71 (헤더 1 + 쿼리 70)
```

### 통계 보기
```bash
python3 << 'EOF'
import csv
with open('data/ground_truth_dev_manual.csv') as f:
    rows = list(csv.DictReader(f))
    total = len(rows)
    no_answer = sum(1 for r in rows if r['document_name'] == 'NO_ANSWER')
    print(f"총 {total}개, 정답 없음 {no_answer}개 ({no_answer/total*100:.1f}%)")
EOF
```

---

**Happy Verifying! 🎉**
